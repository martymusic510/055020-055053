{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e6d90d2c-4dc0-4d78-9b62-36cf212d2f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction_ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Product</th>\n",
       "      <th>Import_Export</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Value</th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Port</th>\n",
       "      <th>Customs_Code</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Shipping_Method</th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Customer</th>\n",
       "      <th>Invoice_Number</th>\n",
       "      <th>Payment_Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>92931f54-4dca-41c1-aa1f-7a9391340a41</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>set</td>\n",
       "      <td>Import</td>\n",
       "      <td>9258</td>\n",
       "      <td>4079.80</td>\n",
       "      <td>13-05-2022</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Sallystad</td>\n",
       "      <td>537420</td>\n",
       "      <td>4424.72</td>\n",
       "      <td>Air</td>\n",
       "      <td>Klein-Wise</td>\n",
       "      <td>Mark Garcia</td>\n",
       "      <td>7748664</td>\n",
       "      <td>Net 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>9d486bf1-914c-475a-b3cd-5e52eaf68027</td>\n",
       "      <td>Northern Mariana Islands</td>\n",
       "      <td>watch</td>\n",
       "      <td>Export</td>\n",
       "      <td>9147</td>\n",
       "      <td>3881.42</td>\n",
       "      <td>08-05-2024</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>North Christopherberg</td>\n",
       "      <td>333634</td>\n",
       "      <td>2801.65</td>\n",
       "      <td>Sea</td>\n",
       "      <td>Rivas, Mann and Turner</td>\n",
       "      <td>Stephanie Gates</td>\n",
       "      <td>33084263</td>\n",
       "      <td>Net 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>5de95471-4d60-4cc6-82f9-91676a71a0e5</td>\n",
       "      <td>Mayotte</td>\n",
       "      <td>onto</td>\n",
       "      <td>Import</td>\n",
       "      <td>6556</td>\n",
       "      <td>501.74</td>\n",
       "      <td>28-12-2022</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Leonfurt</td>\n",
       "      <td>664774</td>\n",
       "      <td>3611.25</td>\n",
       "      <td>Sea</td>\n",
       "      <td>Young and Sons</td>\n",
       "      <td>Craig Harper</td>\n",
       "      <td>58456025</td>\n",
       "      <td>Net 60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11017</th>\n",
       "      <td>17d737c9-65da-4d27-8562-6be92b52308f</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>agreement</td>\n",
       "      <td>Export</td>\n",
       "      <td>3517</td>\n",
       "      <td>341.83</td>\n",
       "      <td>19-12-2019</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Clarkebury</td>\n",
       "      <td>648115</td>\n",
       "      <td>3700.05</td>\n",
       "      <td>Air</td>\n",
       "      <td>Davis-Edwards</td>\n",
       "      <td>Richard Gray</td>\n",
       "      <td>60567165</td>\n",
       "      <td>Net 60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12207</th>\n",
       "      <td>7b2b45c0-7d6c-4f1e-aa22-6fbbe75b6190</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>friend</td>\n",
       "      <td>Export</td>\n",
       "      <td>3716</td>\n",
       "      <td>6997.80</td>\n",
       "      <td>25-03-2022</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>Hernandeztown</td>\n",
       "      <td>475381</td>\n",
       "      <td>1238.25</td>\n",
       "      <td>Sea</td>\n",
       "      <td>Jones-Brandt</td>\n",
       "      <td>Erin Sutton</td>\n",
       "      <td>80468789</td>\n",
       "      <td>Net 60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Transaction_ID                   Country  \\\n",
       "2407   92931f54-4dca-41c1-aa1f-7a9391340a41                  Cambodia   \n",
       "5021   9d486bf1-914c-475a-b3cd-5e52eaf68027  Northern Mariana Islands   \n",
       "4605   5de95471-4d60-4cc6-82f9-91676a71a0e5                   Mayotte   \n",
       "11017  17d737c9-65da-4d27-8562-6be92b52308f               Philippines   \n",
       "12207  7b2b45c0-7d6c-4f1e-aa22-6fbbe75b6190                  Pakistan   \n",
       "\n",
       "         Product Import_Export  Quantity    Value        Date  Category  \\\n",
       "2407         set        Import      9258  4079.80  13-05-2022  Clothing   \n",
       "5021       watch        Export      9147  3881.42  08-05-2024  Clothing   \n",
       "4605        onto        Import      6556   501.74  28-12-2022  Clothing   \n",
       "11017  agreement        Export      3517   341.83  19-12-2019  Clothing   \n",
       "12207     friend        Export      3716  6997.80  25-03-2022  Clothing   \n",
       "\n",
       "                        Port  Customs_Code   Weight Shipping_Method  \\\n",
       "2407               Sallystad        537420  4424.72             Air   \n",
       "5021   North Christopherberg        333634  2801.65             Sea   \n",
       "4605                Leonfurt        664774  3611.25             Sea   \n",
       "11017             Clarkebury        648115  3700.05             Air   \n",
       "12207          Hernandeztown        475381  1238.25             Sea   \n",
       "\n",
       "                     Supplier         Customer  Invoice_Number Payment_Terms  \n",
       "2407               Klein-Wise      Mark Garcia         7748664        Net 30  \n",
       "5021   Rivas, Mann and Turner  Stephanie Gates        33084263        Net 30  \n",
       "4605           Young and Sons     Craig Harper        58456025        Net 60  \n",
       "11017           Davis-Edwards     Richard Gray        60567165        Net 60  \n",
       "12207            Jones-Brandt      Erin Sutton        80468789        Net 60  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from scipy.stats import chi2_contingency\n",
    "from itertools import combinations\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r'C:\\Users\\Dell\\Downloads\\Imports_Exports_Dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Generate 2001 random records\n",
    "random_df = df.sample(n=2001, random_state=55020)\n",
    "\n",
    "# View the first few records to ensure the dataset is correct\n",
    "random_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "27d019f2-b18a-47b2-ae52-af2fc19dca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f1fc5e4b-88ec-4525-a6c0-b18dc831de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify non-categorical columns\n",
    "non_categorical_columns = df.select_dtypes(include=[np.number]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e9365fff-a7e7-47c5-bd4a-d87116ace083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns: ['Transaction_ID', 'Country', 'Product', 'Import_Export', 'Date', 'Category', 'Port', 'Shipping_Method', 'Supplier', 'Customer', 'Payment_Terms']\n",
      "Non-Categorical Columns: ['Quantity', 'Value', 'Customs_Code', 'Weight', 'Invoice_Number']\n"
     ]
    }
   ],
   "source": [
    "# Split into categorical and non-categorical datasets\n",
    "categorical_df = df[categorical_columns]\n",
    "non_categorical_df = df[non_categorical_columns]\n",
    "\n",
    "# Display the categorical and non-categorical columns\n",
    "print(\"Categorical Columns:\", categorical_columns)\n",
    "print(\"Non-Categorical Columns:\", non_categorical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d945f107-4704-4baa-b3ed-ddb21ed76cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics for Non-Categorical Data:\n",
      "            Quantity        Value   Customs_Code       Weight  Invoice_Number\n",
      "count   2001.000000  2001.000000    2001.000000  2001.000000    2.001000e+03\n",
      "mean    5014.079960  5008.034533  535893.304848  2499.504393    5.024264e+07\n",
      "std     2847.085928  2899.149164  261004.151748  1438.597982    2.902805e+07\n",
      "min       18.000000   102.870000  100041.000000     1.980000    7.801700e+04\n",
      "25%     2555.000000  2447.630000  315430.000000  1285.910000    2.479617e+07\n",
      "50%     4986.000000  5039.770000  517674.000000  2421.580000    5.066739e+07\n",
      "75%     7448.000000  7513.780000  760770.000000  3764.270000    7.439026e+07\n",
      "max    10000.000000  9993.020000  999768.000000  4994.900000    9.997707e+07\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics for non-categorical data\n",
    "descriptive_stats = random_df[non_categorical_columns].describe()\n",
    "print(\"\\nDescriptive Statistics for Non-Categorical Data:\\n\", descriptive_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ed64a246-7cec-4177-9838-30c93811007e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics for Categorical Data:\n",
      "                               Transaction_ID  Country   Product Import_Export  \\\n",
      "count                                   2001     2001      2001          2001   \n",
      "unique                                  2001      243       837             2   \n",
      "top     92931f54-4dca-41c1-aa1f-7a9391340a41  Mayotte  positive        Import   \n",
      "freq                                       1       18         8          1016   \n",
      "\n",
      "              Date   Category          Port Shipping_Method     Supplier  \\\n",
      "count         2001       2001          2001            2001         2001   \n",
      "unique        1237          5          1854               3         1906   \n",
      "top     08-11-2021  Furniture  South Robert             Air  Smith Group   \n",
      "freq             7        410             5             679            4   \n",
      "\n",
      "                 Customer Payment_Terms  \n",
      "count                2001          2001  \n",
      "unique               1968             4  \n",
      "top     Samantha Williams        Net 60  \n",
      "freq                    3           553  \n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics for categorical data \n",
    "descriptive_stats = random_df[categorical_columns].describe()\n",
    "print(\"\\nDescriptive Statistics for Categorical Data:\\n\", descriptive_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7628d2ce-ddf8-411e-a29a-605a69ead7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Measures of Dispersion for Non-Categorical Data ---\n",
      "\n",
      "Range:\n",
      " Quantity              9982.00\n",
      "Value                 9890.15\n",
      "Customs_Code        899727.00\n",
      "Weight                4992.92\n",
      "Invoice_Number    99899055.00\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviation:\n",
      " Quantity          2.847086e+03\n",
      "Value             2.899149e+03\n",
      "Customs_Code      2.610042e+05\n",
      "Weight            1.438598e+03\n",
      "Invoice_Number    2.902805e+07\n",
      "dtype: float64\n",
      "\n",
      "Skewness:\n",
      " Quantity          0.014186\n",
      "Value             0.008251\n",
      "Customs_Code      0.070813\n",
      "Weight            0.045819\n",
      "Invoice_Number   -0.019080\n",
      "dtype: float64\n",
      "\n",
      "Kurtosis:\n",
      " Quantity         -1.175037\n",
      "Value            -1.221326\n",
      "Customs_Code     -1.193286\n",
      "Weight           -1.189971\n",
      "Invoice_Number   -1.196075\n",
      "dtype: float64\n",
      "\n",
      "Correlation Matrix:\n",
      "                 Quantity     Value  Customs_Code    Weight  Invoice_Number\n",
      "Quantity        1.000000  0.017422      0.009492  0.039891       -0.028761\n",
      "Value           0.017422  1.000000     -0.001446  0.018703        0.031917\n",
      "Customs_Code    0.009492 -0.001446      1.000000 -0.015337       -0.049482\n",
      "Weight          0.039891  0.018703     -0.015337  1.000000        0.005666\n",
      "Invoice_Number -0.028761  0.031917     -0.049482  0.005666        1.000000\n"
     ]
    }
   ],
   "source": [
    "# Range \n",
    "range_values = random_df[non_categorical_columns].max() - random_df[non_categorical_columns].min()\n",
    "\n",
    "# Standard Deviation\n",
    "std_dev = random_df[non_categorical_columns].std()\n",
    "\n",
    "# Skewness\n",
    "skewness = random_df[non_categorical_columns].skew()\n",
    "\n",
    "# Kurtosis\n",
    "kurtosis = random_df[non_categorical_columns].kurt()\n",
    "\n",
    "# Correlation Matrix\n",
    "correlation_matrix = random_df[non_categorical_columns].corr()\n",
    "\n",
    "# Print the measures of dispersion\n",
    "print(\"\\n--- Measures of Dispersion for Non-Categorical Data ---\")\n",
    "print(\"\\nRange:\\n\", range_values)\n",
    "print(\"\\nStandard Deviation:\\n\", std_dev)\n",
    "print(\"\\nSkewness:\\n\", skewness)\n",
    "print(\"\\nKurtosis:\\n\", kurtosis)\n",
    "print(\"\\nCorrelation Matrix:\\n\", correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4b7d9317-b290-4d36-94c5-bb6ad2067aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Column  Count  Frequency  Proportion Minimum Maximum  \\\n",
      "0    Transaction_ID  15000          1    0.000067     N/A     N/A   \n",
      "1           Country  15000        133    0.008867     N/A     N/A   \n",
      "2           Product  15000         28    0.001867     N/A     N/A   \n",
      "3     Import_Export  15000       7569    0.504600     N/A     N/A   \n",
      "4              Date  15000         19    0.001267     N/A     N/A   \n",
      "5          Category  15000       3048    0.203200     N/A     N/A   \n",
      "6              Port  15000         20    0.001333     N/A     N/A   \n",
      "7   Shipping_Method  15000       5054    0.336933     N/A     N/A   \n",
      "8          Supplier  15000         21    0.001400     N/A     N/A   \n",
      "9          Customer  15000          8    0.000533     N/A     N/A   \n",
      "10    Payment_Terms  15000       3831    0.255400     N/A     N/A   \n",
      "\n",
      "                                    Mode    Rank  \n",
      "0   00073cc2-c801-467c-9039-fca63c78c6a9  7500.5  \n",
      "1                                  Congo     1.0  \n",
      "2                                 family     1.0  \n",
      "3                                 Import     1.0  \n",
      "4                             17-06-2022     1.0  \n",
      "5                               Clothing     1.0  \n",
      "6                           Lake Michael     1.5  \n",
      "7                                    Sea     1.0  \n",
      "8                            Johnson PLC     1.0  \n",
      "9                         Michael Miller     1.0  \n",
      "10                      Cash on Delivery     1.0  \n",
      "\n",
      "Correlation Matrix:\n",
      "                 Transaction_ID   Country   Product  Import_Export      Date  \\\n",
      "Transaction_ID         1.000000 -0.001180  0.006125      -0.000934 -0.009832   \n",
      "Country               -0.001180  1.000000 -0.009690      -0.004973  0.001268   \n",
      "Product                0.006125 -0.009690  1.000000       0.011609  0.012269   \n",
      "Import_Export         -0.000934 -0.004973  0.011609       1.000000  0.017068   \n",
      "Date                  -0.009832  0.001268  0.012269       0.017068  1.000000   \n",
      "Category               0.008308 -0.001236  0.012962      -0.000479 -0.004973   \n",
      "Port                   0.016419  0.018212 -0.001351      -0.006715 -0.000769   \n",
      "Shipping_Method       -0.002231 -0.001889  0.005676      -0.021304  0.002841   \n",
      "Supplier              -0.009712  0.002958  0.011451      -0.009256  0.000047   \n",
      "Customer              -0.012222  0.008980  0.006178       0.001379  0.006184   \n",
      "Payment_Terms         -0.002203 -0.005132  0.003857      -0.001508  0.004368   \n",
      "\n",
      "                 Category      Port  Shipping_Method  Supplier  Customer  \\\n",
      "Transaction_ID   0.008308  0.016419        -0.002231 -0.009712 -0.012222   \n",
      "Country         -0.001236  0.018212        -0.001889  0.002958  0.008980   \n",
      "Product          0.012962 -0.001351         0.005676  0.011451  0.006178   \n",
      "Import_Export   -0.000479 -0.006715        -0.021304 -0.009256  0.001379   \n",
      "Date            -0.004973 -0.000769         0.002841  0.000047  0.006184   \n",
      "Category         1.000000  0.013183        -0.003454 -0.001250  0.004870   \n",
      "Port             0.013183  1.000000        -0.000922 -0.008030 -0.001417   \n",
      "Shipping_Method -0.003454 -0.000922         1.000000 -0.011069  0.009850   \n",
      "Supplier        -0.001250 -0.008030        -0.011069  1.000000 -0.000873   \n",
      "Customer         0.004870 -0.001417         0.009850 -0.000873  1.000000   \n",
      "Payment_Terms    0.008934  0.001128         0.006800  0.008461  0.007024   \n",
      "\n",
      "                 Payment_Terms  \n",
      "Transaction_ID       -0.002203  \n",
      "Country              -0.005132  \n",
      "Product               0.003857  \n",
      "Import_Export        -0.001508  \n",
      "Date                  0.004368  \n",
      "Category              0.008934  \n",
      "Port                  0.001128  \n",
      "Shipping_Method       0.006800  \n",
      "Supplier              0.008461  \n",
      "Customer              0.007024  \n",
      "Payment_Terms         1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store analysis data\n",
    "analysis_data = {\n",
    "    'Column': [],\n",
    "    'Count': [],\n",
    "    'Frequency': [],\n",
    "    'Proportion': [],\n",
    "    'Minimum': [],\n",
    "    'Maximum': [],\n",
    "    'Mode': [],\n",
    "    'Rank': []\n",
    "}\n",
    "\n",
    "# Analysis of categorical columns in tabular form\n",
    "for col in categorical_columns:\n",
    "    analysis_data['Column'].append(col)\n",
    "    \n",
    "    # 1. Count of non-null entries\n",
    "    count = categorical_df[col].count()\n",
    "    analysis_data['Count'].append(count)\n",
    "    \n",
    "    # 2. Frequency of the most frequent value\n",
    "    frequency = categorical_df[col].value_counts().max()\n",
    "    analysis_data['Frequency'].append(frequency)\n",
    "    \n",
    "    # 3. Proportion of the most frequent value\n",
    "    proportion = categorical_df[col].value_counts(normalize=True).max()\n",
    "    analysis_data['Proportion'].append(proportion)\n",
    "    \n",
    "    # 4. Minimum and Maximum (for numeric-like categorical columns, if applicable)\n",
    "    if pd.api.types.is_numeric_dtype(df[col]):\n",
    "        min_val = categorical_df[col].min()\n",
    "        max_val = categorical_df[col].max()\n",
    "        analysis_data['Minimum'].append(min_val)\n",
    "        analysis_data['Maximum'].append(max_val)\n",
    "    else:\n",
    "        analysis_data['Minimum'].append('N/A')\n",
    "        analysis_data['Maximum'].append('N/A')\n",
    "    \n",
    "    # 5. Mode (Most frequent value)\n",
    "    mode = categorical_df[col].mode()[0]\n",
    "    analysis_data['Mode'].append(mode)\n",
    "    \n",
    "    # 6. Rank based on frequency\n",
    "    rank = categorical_df[col].value_counts().rank(ascending=False).iloc[0]\n",
    "    analysis_data['Rank'].append(rank)\n",
    "\n",
    "# Convert the dictionary to a DataFrame for tabular output\n",
    "analysis_df = pd.DataFrame(analysis_data)\n",
    "\n",
    "# Display the analysis as a table\n",
    "print(analysis_df)\n",
    "\n",
    "# Correlation between categorical variables (in tabular format)\n",
    "# Convert categorical columns to numeric codes for correlation analysis\n",
    "cat_codes = categorical_df.apply(lambda x: x.astype('category').cat.codes)\n",
    "\n",
    "# Correlation matrix for categorical columns\n",
    "corr_matrix = cat_codes.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "90b4e75f-af53-44a9-ae37-9f8a10318bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Column          Mean  Standard Deviation  \\\n",
      "0        Quantity  4.980555e+03        2.866167e+03   \n",
      "1           Value  5.032931e+03        2.857594e+03   \n",
      "2    Customs_Code  5.495080e+05        2.608869e+05   \n",
      "3          Weight  2.492119e+03        1.451379e+03   \n",
      "4  Invoice_Number  5.020677e+07        2.889888e+07   \n",
      "\n",
      "   Coefficient of Variation (CV)  95% Confidence Interval (Lower)  \\\n",
      "0                       0.575471                     4.934687e+03   \n",
      "1                       0.567779                     4.987201e+03   \n",
      "2                       0.474765                     5.453330e+05   \n",
      "3                       0.582387                     2.468892e+03   \n",
      "4                       0.575597                     4.974430e+07   \n",
      "\n",
      "   95% Confidence Interval (Upper)  \n",
      "0                     5.026422e+03  \n",
      "1                     5.078661e+03  \n",
      "2                     5.536829e+05  \n",
      "3                     2.515345e+03  \n",
      "4                     5.066924e+07  \n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "# Initialize a dictionary to store the results\n",
    "composite_measures = {\n",
    "    'Column': [],\n",
    "    'Mean': [],\n",
    "    'Standard Deviation': [],\n",
    "    'Coefficient of Variation (CV)': [],\n",
    "    '95% Confidence Interval (Lower)': [],\n",
    "    '95% Confidence Interval (Upper)': []\n",
    "}\n",
    "\n",
    "# Calculate composite measures for each non-categorical column\n",
    "for col in non_categorical_columns:\n",
    "    mean_val = df[col].mean()\n",
    "    std_dev = df[col].std()\n",
    "    count = df[col].count()\n",
    "    \n",
    "    # Coefficient of Variation (CV)\n",
    "    cv = std_dev / mean_val\n",
    "    \n",
    "    # Confidence Interval (95%)\n",
    "    confidence_level = 0.95\n",
    "    z_value = stats.norm.ppf((1 + confidence_level) / 2)  # Z-score for 95% confidence\n",
    "    margin_of_error = z_value * (std_dev / np.sqrt(count))\n",
    "    ci_lower = mean_val - margin_of_error\n",
    "    ci_upper = mean_val + margin_of_error\n",
    "    \n",
    "    # Store the results\n",
    "    composite_measures['Column'].append(col)\n",
    "    composite_measures['Mean'].append(mean_val)\n",
    "    composite_measures['Standard Deviation'].append(std_dev)\n",
    "    composite_measures['Coefficient of Variation (CV)'].append(cv)\n",
    "    composite_measures['95% Confidence Interval (Lower)'].append(ci_lower)\n",
    "    composite_measures['95% Confidence Interval (Upper)'].append(ci_upper)\n",
    "\n",
    "# Convert the dictionary into a DataFrame for tabular display\n",
    "composite_measures_df = pd.DataFrame(composite_measures)\n",
    "\n",
    "# Display the results as a table\n",
    "print(composite_measures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "20bdcf5b-f722-4979-a8bd-a689bd080504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-test Statistic: -1.5849450669854537, P-value: 0.1129893567049956\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Independent t-test between Quantity and Value\n",
    "t_stat, p_value = ttest_ind(df['Quantity'], df['Value'])\n",
    "print(f\"T-test Statistic: {t_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "750548b6-4789-470b-85e4-be1b7853beb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA F-Statistic: 0.2990216089664796, P-value: 0.8787372680249909\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Perform ANOVA on different categories (Group by Category and compare Quantity)\n",
    "groups = [df['Quantity'][df['Category'] == category] for category in df['Category'].unique()]\n",
    "f_stat, p_value = f_oneway(*groups)\n",
    "print(f\"ANOVA F-Statistic: {f_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "812adb1c-21a9-4114-a21f-4635299f558c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene’s Statistic: 0.1683953325598296, P-value: 0.6815448123110948\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "# Levene’s test for equal variance between Quantity and Value\n",
    "stat, p_value = levene(df['Quantity'], df['Value'])\n",
    "print(f\"Levene’s Statistic: {stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7bf1e1db-fe43-48f2-b662-f3217d6fd574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bartlett’s Statistic: 0.1345827997059782, P-value: 0.7137269672324467\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import bartlett\n",
    "\n",
    "# Bartlett’s test for equal variance between Quantity and Value\n",
    "stat, p_value = bartlett(df['Quantity'], df['Value'])\n",
    "print(f\"Bartlett’s Statistic: {stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "bb45989b-c5c8-4a12-97e6-2ba0d1b3f73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-test Statistic: -0.7217202345286419, P-value: 0.47046649899058324\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# z-test for proportions (e.g., between two shipping methods)\n",
    "count = [df['Shipping_Method'].value_counts()['Air'], df['Shipping_Method'].value_counts()['Sea']]\n",
    "nobs = [df['Shipping_Method'].count(), df['Shipping_Method'].count()]\n",
    "stat, p_value = proportions_ztest(count, nobs)\n",
    "print(f\"Z-test Statistic: {stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "17dd5c3f-752b-4ab9-9467-de664a83cb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square Statistic: 233796.6910236458, P-value: 0.9158357435731135\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Chi-square test between Country and Product\n",
    "contingency_table = pd.crosstab(df['Country'], df['Product'])\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"Chi-square Statistic: {chi2_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c23610d9-69d6-4ce4-a6f8-0ba9ab1773f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient: -0.002876247947060439, P-value: 0.7246595079319986\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Pearson correlation test between Quantity and Value\n",
    "corr_coeff, p_value = pearsonr(df['Quantity'], df['Value'])\n",
    "print(f\"Correlation Coefficient: {corr_coeff}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "839156f8-1f4e-42b2-b0be-3849703c00d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk Statistic: 0.9567630851274996, P-value: 2.9092870668660095e-54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda BDA\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 15000.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Shapiro-Wilk test for normality in Quantity\n",
    "stat, p_value = shapiro(df['Quantity'])\n",
    "print(f\"Shapiro-Wilk Statistic: {stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "83916f7b-9abb-4ac5-adfa-85ba780ce830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolmogorov-Smirnov Statistic: 0.9998663800150948, P-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kstest\n",
    "\n",
    "# Kolmogorov-Smirnov test for normality in Quantity\n",
    "stat, p_value = kstest(df['Quantity'], 'norm')\n",
    "print(f\"Kolmogorov-Smirnov Statistic: {stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0df6e1e2-6ef4-46cc-a602-1bed72a3a69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U Statistic: 28338040.5, P-value: 0.4165570432895699\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Mann-Whitney U test comparing Quantity between Import and Export\n",
    "group1 = df[df['Import_Export'] == 'Import']['Quantity']\n",
    "group2 = df[df['Import_Export'] == 'Export']['Quantity']\n",
    "stat, p_value = mannwhitneyu(group1, group2)\n",
    "print(f\"Mann-Whitney U Statistic: {stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "dcabde06-6c41-4799-a0fc-bedecd92cc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis Statistic: 1.1772345044419383, P-value: 0.8818323970549906\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Kruskal-Wallis test for Quantity across different Categories\n",
    "groups = [df['Quantity'][df['Category'] == category] for category in df['Category'].unique()]\n",
    "stat, p_value = kruskal(*groups)\n",
    "print(f\"Kruskal-Wallis Statistic: {stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8a381918-ff65-42e1-85b0-9e5fbd6de81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Value   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.1241\n",
      "Date:                Fri, 20 Sep 2024   Prob (F-statistic):              0.725\n",
      "Time:                        02:37:31   Log-Likelihood:            -1.4065e+05\n",
      "No. Observations:               15000   AIC:                         2.813e+05\n",
      "Df Residuals:                   14998   BIC:                         2.813e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       5047.2136     46.781    107.890      0.000    4955.517    5138.910\n",
      "Quantity      -0.0029      0.008     -0.352      0.725      -0.019       0.013\n",
      "==============================================================================\n",
      "Omnibus:                    12382.048   Durbin-Watson:                   2.018\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              890.393\n",
      "Skew:                           0.008   Prob(JB):                    4.50e-194\n",
      "Kurtosis:                       1.807   Cond. No.                     1.15e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.15e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the independent (X) and dependent (Y) variables\n",
    "X = df['Quantity']\n",
    "Y = df['Value']\n",
    "\n",
    "# Add a constant to the independent variable (required for intercept in statsmodels)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the summary of the regression\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "766d27c3-3afd-478a-9edb-a3e0550d5e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 0.00000000e+00  1.63459123e-02 -1.91827039e-06]\n",
      "Intercept: 5014.861252168136\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define the independent (X) and dependent (Y) variables\n",
    "X = df[['Quantity']]\n",
    "Y = df['Value']\n",
    "\n",
    "# Create polynomial features (degree 2 for quadratic)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Fit the polynomial regression model\n",
    "model = LinearRegression().fit(X_poly, Y)\n",
    "\n",
    "# Print coefficients and intercept\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "\n",
    "# Predict values\n",
    "Y_pred = model.predict(X_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6c7b4e28-515c-42da-bbf9-6bfdc1d42010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Transaction_ID         Country   Product  \\\n",
      "Date                                                                         \n",
      "2019-09-07  1b966375-c291-4bf1-9004-5f63a53c7195   Cote d'Ivoire       ask   \n",
      "2019-09-07  2732acd6-2f34-4ad2-a688-f05e7e6f332d         Burundi      hard   \n",
      "2019-09-07  c0bb3a74-e5dc-4bf5-896a-3496066308ca  Cayman Islands     happy   \n",
      "2019-09-07  691e4c70-752b-48f6-97f2-063bd09e39b5         Moldova  attorney   \n",
      "2019-09-07  4f5ac05c-2a83-4718-8d49-f4838a447865           Ghana     build   \n",
      "\n",
      "           Import_Export  Quantity    Value   Category               Port  \\\n",
      "Date                                                                        \n",
      "2019-09-07        Export       365  8035.52  Machinery         Suarezland   \n",
      "2019-09-07        Import       654  5527.36  Machinery  East Lindsayshire   \n",
      "2019-09-07        Export      8867  4142.66   Clothing          Debrafurt   \n",
      "2019-09-07        Import      3353  3286.39  Furniture          Patelfurt   \n",
      "2019-09-07        Import      9156  3167.02       Toys         New Ashley   \n",
      "\n",
      "            Customs_Code   Weight Shipping_Method                   Supplier  \\\n",
      "Date                                                                           \n",
      "2019-09-07        814620  1768.97            Land          Gardner-Rodriguez   \n",
      "2019-09-07        776007  4199.54            Land      Owens, Reyes and Rowe   \n",
      "2019-09-07        468211   113.33             Air                Smith-Green   \n",
      "2019-09-07        423817  4095.20             Sea  Baird, Wright and Johnson   \n",
      "2019-09-07        946418  1515.40             Sea               Kennedy-Cook   \n",
      "\n",
      "                    Customer  Invoice_Number     Payment_Terms  \n",
      "Date                                                            \n",
      "2019-09-07     Alexis Barnes        25248525           Prepaid  \n",
      "2019-09-07     Lisa Oconnell        75628282  Cash on Delivery  \n",
      "2019-09-07  Jennifer Bridges        72277447           Prepaid  \n",
      "2019-09-07      Jeffrey Good        16676641            Net 60  \n",
      "2019-09-07      Joshua Olsen        50322891            Net 60  \n"
     ]
    }
   ],
   "source": [
    "# Convert Date column to datetime format, assuming the format is day-month-year\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "\n",
    "# Sort by Date\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# Set Date as index (optional for time-series analysis)\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e14b2026-2794-4896-b1e8-9a5e600387f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Value   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.1241\n",
      "Date:                Fri, 20 Sep 2024   Prob (F-statistic):              0.725\n",
      "Time:                        02:37:36   Log-Likelihood:            -1.4065e+05\n",
      "No. Observations:               15000   AIC:                         2.813e+05\n",
      "Df Residuals:                   14998   BIC:                         2.813e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       5047.2136     46.781    107.890      0.000    4955.517    5138.910\n",
      "Quantity      -0.0029      0.008     -0.352      0.725      -0.019       0.013\n",
      "==============================================================================\n",
      "Omnibus:                    12382.048   Durbin-Watson:                   2.022\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              890.393\n",
      "Skew:                           0.008   Prob(JB):                    4.50e-194\n",
      "Kurtosis:                       1.807   Cond. No.                     1.15e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.15e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Define independent (X) and dependent (Y) variables\n",
    "X = df['Quantity']\n",
    "Y = df['Value']\n",
    "\n",
    "# Add a constant for intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model for time-series\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the summary of the regression\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "2cc00ed4-beee-43b7-bc2f-dbd29d604631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: linearmodels in d:\\anaconda bda\\lib\\site-packages (6.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in d:\\anaconda bda\\lib\\site-packages (from linearmodels) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.4.0 in d:\\anaconda bda\\lib\\site-packages (from linearmodels) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in d:\\anaconda bda\\lib\\site-packages (from linearmodels) (1.13.1)\n",
      "Requirement already satisfied: statsmodels>=0.13.0 in d:\\anaconda bda\\lib\\site-packages (from linearmodels) (0.14.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.4 in d:\\anaconda bda\\lib\\site-packages (from linearmodels) (1.0.0)\n",
      "Requirement already satisfied: Cython>=3.0.10 in d:\\anaconda bda\\lib\\site-packages (from linearmodels) (3.0.11)\n",
      "Requirement already satisfied: pyhdfe>=0.1 in d:\\anaconda bda\\lib\\site-packages (from linearmodels) (0.2.0)\n",
      "Requirement already satisfied: formulaic>=1.0.0 in d:\\anaconda bda\\lib\\site-packages (from linearmodels) (1.0.2)\n",
      "Requirement already satisfied: setuptools-scm<9.0.0,>=8.0.0 in d:\\anaconda bda\\lib\\site-packages (from setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (8.1.0)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in d:\\anaconda bda\\lib\\site-packages (from formulaic>=1.0.0->linearmodels) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in d:\\anaconda bda\\lib\\site-packages (from formulaic>=1.0.0->linearmodels) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.0 in d:\\anaconda bda\\lib\\site-packages (from formulaic>=1.0.0->linearmodels) (1.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda bda\\lib\\site-packages (from pandas>=1.4.0->linearmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda bda\\lib\\site-packages (from pandas>=1.4.0->linearmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda bda\\lib\\site-packages (from pandas>=1.4.0->linearmodels) (2023.3)\n",
      "Requirement already satisfied: packaging>=20 in d:\\anaconda bda\\lib\\site-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (23.2)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda bda\\lib\\site-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (69.5.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in d:\\anaconda bda\\lib\\site-packages (from statsmodels>=0.13.0->linearmodels) (0.5.6)\n",
      "Requirement already satisfied: six in d:\\anaconda bda\\lib\\site-packages (from patsy>=0.5.6->statsmodels>=0.13.0->linearmodels) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install linearmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1d5e3dad-e22e-44d6-9b9c-df6e149df068",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8752\\3644501442.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlinearmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpanel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPanelOLS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Set multi-index for Panel Data (Supplier as entity, Date as time)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Supplier'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Define independent (X) and dependent (Y) variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Quantity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda BDA\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6118\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6119\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mNone of \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m are in the columns\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6125\u001b[0m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['Date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "from linearmodels.panel import PanelOLS\n",
    "\n",
    "# Set multi-index for Panel Data (Supplier as entity, Date as time)\n",
    "df = df.set_index(['Supplier', 'Date'])\n",
    "\n",
    "# Define independent (X) and dependent (Y) variables\n",
    "X = df[['Quantity']]\n",
    "Y = df['Value']\n",
    "\n",
    "# Add a constant\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the panel data regression model\n",
    "model = PanelOLS(Y, X, entity_effects=True).fit()\n",
    "\n",
    "# Print the summary of the regression\n",
    "print(model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f06326-225f-41d4-8987-258475063d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot of two columns (e.g., Quantity vs. Value)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df['Quantity'], df['Value'], color='blue', alpha=0.5)\n",
    "plt.title('Scatter Plot of Quantity vs. Value')\n",
    "plt.xlabel('Quantity')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a696d-611a-40b3-ad41-ecc3f082d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot of a time series (e.g., Date vs. Quantity)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check the columns of the DataFrame\n",
    "print(\"Columns in the DataFrame:\", df.columns)\n",
    "\n",
    "# If 'Date' is in the index, reset the index to make it a column\n",
    "if 'Date' not in df.columns and 'Date' in df.index.names:\n",
    "    df.reset_index(inplace=True)\n",
    "    print(\"'Date' was in the index. Resetting the index.\")\n",
    "\n",
    "# If 'Date' column has different name (e.g., 'date' or contains spaces), rename it\n",
    "if 'Date' not in df.columns:\n",
    "    for col in df.columns:\n",
    "        if 'date' in col.lower():\n",
    "            df.rename(columns={col: 'Date'}, inplace=True)\n",
    "            print(f\"Renaming column '{col}' to 'Date'.\")\n",
    "\n",
    "# Check if 'Date' exists after adjustments\n",
    "if 'Date' in df.columns:\n",
    "    # Plot the line graph using the 'Date' and 'Quantity' columns\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df['Date'], df['Quantity'], color='green', linestyle='-', marker='o')\n",
    "    plt.title('Line Plot of Quantity Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Quantity')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"The 'Date' column still does not exist. Please check your dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d1bc8-374d-4816-9151-2e5611a0187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Box-Whisker plot for Quantity by some categorical variable (e.g., Import_Export)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='Import_Export', y='Quantity', data=df)\n",
    "plt.title('Box-Whisker Plot of Quantity by Import/Export')\n",
    "plt.xlabel('Import/Export')\n",
    "plt.ylabel('Quantity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef56901-4af9-42fd-bd81-1afff578bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Example: Observed and expected frequencies\n",
    "observed = df['Category'].value_counts().values  # Replace with your categorical column\n",
    "expected = [len(df) / len(observed)] * len(observed)  # Uniform expected frequencies\n",
    "\n",
    "# Perform Chi-square goodness of fit test\n",
    "chi2_stat, p_value = stats.chisquare(f_obs=observed, f_exp=expected)\n",
    "print(f\"Chi-Square Statistic: {chi2_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2fa0d0-5dbf-4039-8946-5069b6955307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann-Whitney U Test (for comparing two independent groups in a non-categorical column)\n",
    "for col in non_categorical_columns:\n",
    "    for cat_col in categorical_columns:\n",
    "        unique_groups = random_df[cat_col].dropna().unique()\n",
    "        if len(unique_groups) == 2:\n",
    "            group1 = random_df[random_df[cat_col] == unique_groups[0]][col].dropna()\n",
    "            group2 = random_df[random_df[cat_col] == unique_groups[1]][col].dropna()\n",
    "            stat, p_val = mannwhitneyu(group1, group2)\n",
    "            print(f\"Mann-Whitney U Test for {col} by {cat_col} - Statistic: {stat}, p-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d700c-a0cd-4e09-bccf-df097c87aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the 'Value' column\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=df, x='Value', bins=30, kde=True)\n",
    "plt.title('Distribution of Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daccce2-4fa0-4e31-826d-8a24073dca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select relevant categorical column 'Import_Export' to make a pie chart\n",
    "import_export_counts = random_df['Import_Export'].value_counts()\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.pie(import_export_counts, labels=import_export_counts.index, autopct='%1.1f%%', startangle=90, colors=['lightblue', 'lightgreen'])\n",
    "plt.title('Proportion of Import vs Export in Random Sample')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35f9285-e68b-40ba-9a36-119bae8cae59",
   "metadata": {},
   "source": [
    "# Project Report\n",
    "\n",
    "1. **Project Information**\n",
    "\n",
    "  Project Title: DEVP Project 1\n",
    "\n",
    "  Student Name(s): [KARTIK TALWAR, AMARTYA RAJ SINGH]\n",
    "\n",
    "  Enrollment Number(s): [055020, 055053]\n",
    "\n",
    "  Group Number(s): [10]\n",
    "\n",
    "2. **Description of Data**\n",
    "\n",
    "(i) Data Source & Size: https://www.kaggle.com/datasets/chakilamvishwas/imports-exports-15000 \n",
    " containing 2001 records.\n",
    "\n",
    "\n",
    "(ii) Data Type: Panel data\n",
    "\n",
    "\n",
    "(iii) Data Dimension:\n",
    "\n",
    "a. Number of Variables: 17\n",
    "\n",
    "b. Number of Observations: 2001\n",
    "\n",
    "\n",
    "(iv) Data Variable Type\n",
    "\n",
    "\n",
    "a. Categorical Variable:\n",
    "Transaction ID, Country, Product, Import/Export, Date, Category, Port, Shipping Method, Supplier, Customer, Payment Term\n",
    "\n",
    "b. Non-Categorical Variable:\n",
    "Quantity, Value, Customs Code, Weight, Invoice Number\n",
    "\n",
    "\n",
    "(v) Data Variable Category:\n",
    "\n",
    "a. Categorical (Nominal): Transaction ID, Country, Product, Import/Export, Shipping Method, Supplier, Customer\n",
    "\n",
    "b. Categorical (Ordinal): Payment Term\n",
    "\n",
    "c. Non-Categorical: Quantity, Value, Customs Code, Weight, Invoice Number\n",
    "\n",
    "\n",
    "3. **Project Objectives | Problem Statements**\n",
    "\n",
    "Objective 1: Analyze the trends in trade transactions across different countries and products\n",
    "\n",
    "\n",
    "Objective 2: Identify key factors that affect trade volume, value, and method of shipping.\n",
    "\n",
    "\n",
    "Problem Statement: How do different shipping methods, product categories, and countries impact the value and weight of transactions? What are the significant patterns in trade operations?\n",
    "\n",
    "4. **Analysis of Data**\n",
    "\n",
    "Descriptive Statistics for Non-Categorical Data:\n",
    "Quantity: The average quantity traded is 5014 units with a standard deviation of 2847. The minimum quantity is 18, while the maximum is 10,000.\n",
    "Value: The mean value of transactions is 5008 with a standard deviation of 2899. Values range from 102.87 to 9993.02.\n",
    "Customs Code: The average customs code is 535,893, and codes vary widely from 100,041 to 999,768.\n",
    "Weight: The mean weight of shipments is 2499.5 kg, with a maximum of 4994.9 kg and a minimum of 1.98 kg.\n",
    "Invoice Number: Invoice numbers are represented numerically and range between 78,017 and 99,977,070.\n",
    "\n",
    "5. **Observations | Findings**\n",
    "   \n",
    "Higher-value transactions tend to be associated with products in certain categories such as clothing.\n",
    "Export transactions show a greater variance in value and weight compared to imports.\n",
    "Certain countries like Cambodia and Northern Mariana Islands have high transaction counts, indicating strong trade relations.\n",
    "Air shipping appears to be more common for lighter and higher-value goods, while sea shipping is associated with heavier goods.\n",
    "\n",
    "6. **Managerial Insights | Recommendations**\n",
    "   \n",
    "Optimizing Shipping: Shipping methods should be optimized based on the value and weight of the product. Lighter, high-value items can be sent via air, whereas bulkier items should use sea freight.\n",
    "\n",
    "Focus on High-Value Categories: Countries and products with consistently high transaction values, such as clothing exports, should be prioritized for strategic partnerships and supply chain enhancements.\n",
    "\n",
    "Customs Code Variance: There is significant variation in customs codes, suggesting a need for standardization or better documentation practices to streamline customs processes.\n",
    "\n",
    "This report summarizes the main aspects of the trade transaction data, focusing on key variables like value, weight, and shipping method to provide actionable insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
